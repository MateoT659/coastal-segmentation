{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c023d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 Model Architecture\n",
    "\n",
    "class vgg16_conv_block(nn.Module):\n",
    "    def __init__(self, input_channels, out_channels, dropout_rate=0.3, drop=True):\n",
    "        # A convolutional block of a vgg containing a convolution, batch norm, relu, and a dropout layer.\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, out_channels, 3, 1, 1)  #This line creates a 2D convolutional layer using PyTorch's nn.Conv2d module.\n",
    "        self.bn = nn.BatchNorm2d(out_channels) # normalize the activations of the convolutional layer in the neural network.\n",
    "        self.relu = nn.ReLU(inplace=True) #introduces non-linearity (-ve --> zeros)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.drop = drop\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn(self.conv(x)))\n",
    "        if self.drop:\n",
    "            x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "def vgg16_layer(input_channels, out_channels, num_blocks, dropout_rate=0.3):\n",
    "    # A layer of vgg blocks, ending with a 2x2 max pooling layer.\n",
    "    \n",
    "    layers = []\n",
    "    for _ in range(num_blocks): \n",
    "        layers.append(vgg16_conv_block(input_channels, out_channels, dropout_rate))\n",
    "        input_channels = out_channels\n",
    "    layers.append(nn.MaxPool2d(2, 2))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self, input_channels = 3, num_classes=10, dropout_rates=[0.3, 0.4], convlayers = [16, 32, 64, 128, 256, 512, 512], netlayers = [4096, 4096], input_size = context_width):\n",
    "        # A full VGG model, with modifiable convolutional layer and fully connected layer parameters        \n",
    "\n",
    "        convlayers = [input_channels] + convlayers # Create input channel layer\n",
    "\n",
    "        final_size = input_size // (2**(len(convlayers)-1))\n",
    "        netlayers = [convlayers[-1]*final_size*final_size] + netlayers + [num_classes] # Add a net layer for the final feature map size and the number of classes\n",
    "\n",
    "        super(VGG16, self).__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            *(vgg16_layer(convlayers[i], convlayers[i+1], 2, dropout_rates[0]) for i in range(len(convlayers)-1))\n",
    "        )\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Dropout(dropout_rates[1]),\n",
    "            nn.Flatten(),\n",
    "            *(nn.Linear(netlayers[i], netlayers[i+1], bias=True) for i in range(len(netlayers)-1))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a2aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "distribution = [0]*7\n",
    "\n",
    "pathX = '../data/dataset/X'\n",
    "pathY = '../data/dataset/y'\n",
    "files = [f for f in os.listdir(pathX) if f.endswith('.tif')]\n",
    "\n",
    "# load data from files\n",
    "for file in files:\n",
    "    X.append(rio.open(os.path.join(pathX, file)).read())\n",
    "    y.append(rio.open(os.path.join(pathY, file)).read())\n",
    "\n",
    "# flatten outputs\n",
    "for i in range(len(X)):\n",
    "    X[i] = np.moveaxis(X[i], 0, -1)\n",
    "    y[i] = np.moveaxis(y[i], 0, -1).flatten()\n",
    "\n",
    "    for j in range(len(y[i])):\n",
    "        distribution[y[i][j]] += 1\n",
    "\n",
    "    one_hot = np.zeros(decision_width*decision_width*7, dtype=int)  # Create a one-hot encoded array\n",
    "    for j in range(len(y[i])):\n",
    "        one_hot[j*7+y[i][j]] = 1\n",
    "\n",
    "    y[i] = one_hot.astype(np.int8)\n",
    "\n",
    "distribution = np.array(distribution)\n",
    "distribution = distribution / np.sum(distribution)\n",
    "\n",
    "print('X shape:', np.array(X).shape)\n",
    "print('y shape:', np.array(y).shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46de63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = VGG16(\n",
    "    input_channels=8,\n",
    "    num_classes=decision_width*decision_width*7,\n",
    "    convlayers=convlayers,\n",
    "    netlayers=netlayers,\n",
    ").to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) #Adam optimizer with a learning rate of 0.001.\n",
    "\n",
    "\n",
    "# input augmentation with transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), #Convert the data to PyTorch tensors.\n",
    "])\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "dataset = CustomDataset(X, y, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset)) #80% of the data for training.\n",
    "test_size = len(dataset) - train_size #20% of the data for testing.\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size]) #Splitting the dataset into training and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffba9b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function and Class Weighting\n",
    "\n",
    "class_weights = 1/distribution\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device) #Convert the class weights to a PyTorch tensor and move it to the device (GPU or CPU).\n",
    "\n",
    "cross_entropy = torch.nn.CrossEntropyLoss(reduction='none', weight=class_weights) #Cross entropy loss function with inverse class weights.\n",
    "\n",
    "# Custom loss function to weight individual cross entropies.\n",
    "def loss_fn(outputs, labels, error_margin = 1):\n",
    "    # the error margin is how far the predicted class can be from an instance of the true class before being counted as an error.\n",
    "    losses = []\n",
    "\n",
    "    outputs = outputs.reshape(decision_width, decision_width, 7)\n",
    "    labels = labels.reshape(decision_width, decision_width, 7)\n",
    "    labels = labels.argmax(axis=2)\n",
    "\n",
    "    for i in range(0, decision_width):\n",
    "        for j in range(0, decision_width):\n",
    "            output = outputs[i, j]\n",
    "            label = labels[i, j]\n",
    "            \n",
    "            # Relaxed Error\n",
    "            # predicted_class = output.argmax()\n",
    "\n",
    "            # margin = labels[max(0, i-error_margin):i+error_margin, max(0, j-error_margin):j+error_margin]\n",
    "\n",
    "            # if predicted_class in margin:\n",
    "            #     label = torch.Tensor(predicted_class).to(device)    \n",
    "\n",
    "            loss = cross_entropy(output, label)\n",
    "            losses.append(loss)\n",
    "    \n",
    "    return torch.stack(losses).mean()\n",
    "\n",
    "# Directly weighing dataset by class combination. (sum of weights)\n",
    "# weights = torch.tensor(np.zeros(len(train_dataset)), dtype=torch.float32) #Initialize weights to zero.\n",
    "# \n",
    "# for i in range(len(train_dataset)): #loop through each training sample\n",
    "#     train = train_dataset[i][1].reshape(decision_width*decision_width, 7).argmax(axis=1) #Reshape the training sample to a 2D array.\n",
    "#     for cl in train:\n",
    "#         weights[i] += classWeights[cl] #Add the class weight to the sample weight.\n",
    "# sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "# \n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False) #DataLoader for testing data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1609e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "\n",
    "best_epoch = 0\n",
    "min_loss = float('inf') #Initialize minimum loss to infinity.\n",
    "global_start_time = time.time() #Start time for training.\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    epoch_start_time = time.time() #Start time for epoch.\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = [loss_fn(out, label) for out, label in zip(outputs, labels)] #Calculate the loss.\n",
    "        loss = torch.stack(loss).mean()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += batch_size*decision_width*decision_width #Total number of samples.\n",
    "        running_loss += loss.item() #Accumulate loss.\n",
    "\n",
    "        # calculating accuracy\n",
    "        for label, output in zip(labels, outputs):\n",
    "            for i in range(0, len(label), 7):\n",
    "                correct+= (torch.argmax(label[i:i+7]) == torch.argmax(output[i:i+7])).item() #Count correct predictions.\n",
    "\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Accuracy: {100 * correct / total:.2f}%, Time: {time.time() - epoch_start_time:.2f}s')\n",
    "\n",
    "    # save best model\n",
    "    if min_loss >= running_loss:\n",
    "        min_loss = running_loss\n",
    "        best_epoch = epoch + 1\n",
    "        torch.save(model.state_dict(), f'vgg16_trained.pth')\n",
    "\n",
    "# load best model\n",
    "model.load_state_dict(torch.load(f'vgg16_trained.pth'))\n",
    "print(f'\\nBest Loss: {min_loss/len(train_loader):.4f}, Epoch {best_epoch} model saved.')\n",
    "print(f'Total Training Time: {time.time() - global_start_time:.2f}s, Average Time per Epoch: {(time.time() - global_start_time)/num_epochs:.2f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "running_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device) #Move data to GPU if available.\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = [loss_fn(out, label) for out, label in zip(outputs, labels)] #Calculate the loss.\n",
    "        loss = torch.stack(loss).mean()\n",
    "\n",
    "        running_loss += loss.item() #Accumulate loss.\n",
    "        total += labels.size(0)*decision_width*decision_width #Total number of samples.\n",
    "        \n",
    "        for label, output in zip(labels, outputs):\n",
    "            for i in range(0, len(label), 7):\n",
    "                correct+= (torch.argmax(label[i:i+7]) == torch.argmax(output[i:i+7])).item() #Count correct predictions.\n",
    "\n",
    "accuracy = 100 * correct / total #Calculate accuracy.\n",
    "\n",
    "print(f'Test Loss: {running_loss/len(test_loader):.4f}, Test Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0167ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Model Predictions\n",
    "inputs, labels = random.choice(list(test_loader))\n",
    "inputs, labels = inputs.to(device), labels.to(device) #Move data to GPU if available.\n",
    "\n",
    "outputs = model(inputs)\n",
    "outputs = outputs.cpu().detach().numpy()\n",
    "labels = labels.cpu().detach().numpy()\n",
    "\n",
    "for _ in range(3):\n",
    "    ind = random.randint(0, len(inputs)-1)\n",
    "    input, label, output = inputs[ind], labels[ind], outputs[ind] \n",
    "    \n",
    "    # show 8 input bands\n",
    "    for band in range(8):\n",
    "        plt.subplot(1, 10, band+1)\n",
    "        plt.imshow(input[band].cpu().numpy(), cmap='gray')\n",
    "        plt.title('Band {}'.format(band+1))\n",
    "        plt.axis('off')\n",
    "\n",
    "    # show output and label\n",
    "    plt.subplot(1,10,9)\n",
    "    plt.imshow(label.reshape(decision_width, decision_width, 7).argmax(axis=2), cmap='gray')\n",
    "    plt.title('Label')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1,10,10)\n",
    "    plt.imshow(output.reshape(decision_width, decision_width, 7).argmax(axis=2), cmap='gray')\n",
    "    plt.title('Output')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687a8e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class Metrics\n",
    "\n",
    "# calculate tp, tn, fp, fn for each class, then APRF1 ([[]*4]*7)\n",
    "labelcount = {i:0 for i in range(7)}\n",
    "outcount = {i:0 for i in range(7)}\n",
    "tp = [0]*7\n",
    "fp = [0]*7\n",
    "fn = [0]*7\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, yi in zip(X, y):\n",
    "        x = torch.tensor(x, dtype=torch.float32).to(device)\n",
    "        x = x.permute(2, 0, 1) # Move channels to first dimension\n",
    "        x = x.unsqueeze(0) # Add batch dimension\n",
    "\n",
    "        out = model(x)\n",
    "\n",
    "        out = out.flatten()\n",
    "\n",
    "        for i in range(0, len(yi), 7):\n",
    "            outlabel = torch.argmax(out[i:i + 7])\n",
    "            label = torch.argmax(torch.tensor(yi[i:i + 7]))\n",
    "\n",
    "            labelcount[label.item()] += 1\n",
    "            outcount[outlabel.item()] += 1\n",
    "\n",
    "            if label.item() == outlabel.item():\n",
    "                tp[label.item()] += 1\n",
    "            else:\n",
    "                fp[outlabel.item()] += 1\n",
    "                fn[label.item()] += 1\n",
    "        \n",
    "outcount = dict(sorted(outcount.items()))\n",
    "labelcount = dict(sorted(labelcount.items()))\n",
    "\n",
    "precisions = [0]*7\n",
    "recalls = [0]*7\n",
    "\n",
    "for i in range(7):\n",
    "    if tp[i] + fp[i] != 0:\n",
    "        precisions[i] = tp[i] / (tp[i] + fp[i])\n",
    "    if tp[i] + fn[i] != 0:\n",
    "        recalls[i] = tp[i] / (tp[i] + fn[i])\n",
    "\n",
    "print(\"True Positives:\", tp)\n",
    "print(\"False Positives:\", fp)\n",
    "print(\"False Negatives:\", fn)\n",
    "\n",
    "# plot deviation bar diagram using the % error of the counts from the model and the counts from the labels \n",
    "# (higher value -> model overpredicts, lower value -> model underpredicts)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar(classNames.values(), [(outcount[i] - labelcount[i] )/(labelcount[i] + 1e-6) for i in labelcount.keys()], color=classColorsNormalized.values(), alpha=0.7)\n",
    "plt.title('Percent Error of Model Prediction Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Error')\n",
    "# plt.ylim(-1, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# plot precision and recall histograms in subplot\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(classNames.values(), precisions, color=classColorsNormalized.values(), alpha=0.7)\n",
    "plt.title('Precision')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(classNames.values(), recalls, color=classColorsNormalized.values(), alpha=0.7)\n",
    "plt.title('Recall')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Recall')\n",
    "plt.ylim(0, 1)\n",
    "plt.xticks(rotation=45)\n",
    "plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682fa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Image Prediction\n",
    "\n",
    "generation_start_time = time.time() #Start time for full image prediction.\n",
    "path = '../data/raw_labeled_data/images/'\n",
    "pathY = '../data/raw_labeled_data/annotations/'\n",
    "files = [f for f in os.listdir(path) if f.endswith('.tif')]\n",
    "\n",
    "\n",
    "padding_width = (context_width - decision_width) // 2\n",
    "for file in files:\n",
    "\n",
    "    imgX = rio.open(os.path.join(path, file)).read()\n",
    "    imgX = np.pad(imgX, ((0, 0), (padding_width, padding_width), (padding_width, padding_width)), mode='edge')\n",
    "    imgX = np.moveaxis(imgX, 0, -1)  # Move the channel dimension to the last position\n",
    "\n",
    "    imgY = rio.open(os.path.join(pathY, file)).read()[0]\n",
    "\n",
    "\n",
    "    # color and display label\n",
    "    colored_imgY = np.zeros((imgY.shape[0], imgY.shape[1], 3), dtype=np.uint8)\n",
    "    for class_id, color in classColors.items():\n",
    "        colored_imgY[imgY == class_id] = color\n",
    "\n",
    "    plt.imshow(colored_imgY)\n",
    "    plt.title('Colored Label')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # predict full image\n",
    "    out = np.zeros((imgY.shape[0], imgY.shape[1], 1), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, imgX.shape[0]-context_width, decision_width):\n",
    "        for j in range(0, imgX.shape[1]-context_width, decision_width):\n",
    "            x = torch.from_numpy(imgX[i:i + context_width, j:j + context_width, :]).float().to(device)\n",
    "            x = x.permute(2, 0, 1).unsqueeze(0)  # Add batch dimension and permute to (batch_size, channels, height, width)\n",
    "            \n",
    "            out1 = model(x)\n",
    "            out1 = out1.cpu().detach().numpy()\n",
    "            out[i:i + decision_width, j:j + decision_width, :] = out1.reshape(decision_width, decision_width, 7).argmax(axis=2).reshape(decision_width, decision_width, 1)    \n",
    "        \n",
    "        if i//decision_width % 5 == 0:\n",
    "            print(f\"{i/imgX.shape[0]*100:.2f}% done\")\n",
    "    output_path = os.path.join('../masksVGG/training/', file)\n",
    "    with rio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out.shape[0],\n",
    "        width=out.shape[1],\n",
    "        count=1,\n",
    "        dtype=out.dtype,\n",
    "        crs=rio.open(os.path.join(path, file)).crs,\n",
    "        transform=rio.open(os.path.join(path, file)).transform,\n",
    "    ) as dst:\n",
    "        dst.write(out[:, :, 0], 1)\n",
    "\n",
    "    colored_out = np.zeros((out.shape[0], out.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in classColors.items():\n",
    "        colored_out[out[:, :, 0] == class_id] = color\n",
    "\n",
    "    plt.imshow(colored_out)\n",
    "    plt.title('Colored Output')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'Image Segmentation Time: {time.time() - generation_start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa06c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Image Prediction\n",
    "\n",
    "generation_start_time = time.time() #Start time for full image prediction.\n",
    "path = '../data/test_data/3/images/'\n",
    "pathY = '../data/test_data/3/colored/'\n",
    "files = [f for f in os.listdir(path) if f.endswith('.tif')]\n",
    "filesy = [f for f in os.listdir(pathY) if f.endswith('.png')]\n",
    "\n",
    "\n",
    "padding_width = (context_width - decision_width) // 2\n",
    "for file, yfile in zip(files, filesy):\n",
    "\n",
    "    imgX = rio.open(os.path.join(path, file)).read()\n",
    "    imgX = np.pad(imgX, ((0, 0), (padding_width, padding_width), (padding_width, padding_width)), mode='edge')\n",
    "    imgX = np.moveaxis(imgX, 0, -1)  # Move the channel dimension to the last position\n",
    "\n",
    "    imgY = rio.open(os.path.join(pathY, yfile)).read()\n",
    "    imgY = np.moveaxis(imgY, 0, -1)  # Move the channel dimension to the last position\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # color and display label\n",
    "\n",
    "    plt.imshow(imgY)\n",
    "    plt.title('image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # predict full image\n",
    "    out = np.zeros((imgY.shape[0], imgY.shape[1], 1), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, imgX.shape[0]-context_width, decision_width):\n",
    "        for j in range(0, imgX.shape[1]-context_width, decision_width):\n",
    "            x = torch.from_numpy(imgX[i:i + context_width, j:j + context_width, :]).float().to(device)\n",
    "            x = x.permute(2, 0, 1).unsqueeze(0)  # Add batch dimension and permute to (batch_size, channels, height, width)\n",
    "            \n",
    "            out1 = model(x)\n",
    "            out1 = out1.cpu().detach().numpy()\n",
    "            out[i:i + decision_width, j:j + decision_width, :] = out1.reshape(decision_width, decision_width, 7).argmax(axis=2).reshape(decision_width, decision_width, 1)    \n",
    "        \n",
    "        if i//decision_width % 5 == 0:\n",
    "            print(f\"{i/imgX.shape[0]*100:.2f}% done\")\n",
    "\n",
    "    output_path = os.path.join('../masksVGG/3/', file)\n",
    "    with rio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out.shape[0],\n",
    "        width=out.shape[1],\n",
    "        count=1,\n",
    "        dtype=out.dtype,\n",
    "        crs=rio.open(os.path.join(path, file)).crs,\n",
    "        transform=rio.open(os.path.join(path, file)).transform,\n",
    "    ) as dst:\n",
    "        dst.write(out[:, :, 0], 1)\n",
    "        \n",
    "    colored_out = np.zeros((out.shape[0], out.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in classColors.items():\n",
    "        colored_out[out[:, :, 0] == class_id] = color\n",
    "\n",
    "    plt.imshow(colored_out)\n",
    "    plt.title('Colored Output')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'Image Segmentation Time: {time.time() - generation_start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Image Prediction\n",
    "\n",
    "generation_start_time = time.time() #Start time for full image prediction.\n",
    "path = '../data/test_data/1/images/'\n",
    "pathY = '../data/test_data/1/colored/'\n",
    "files = [f for f in os.listdir(path) if f.endswith('.tif')]\n",
    "filesy = [f for f in os.listdir(pathY) if f.endswith('.png')]\n",
    "\n",
    "\n",
    "padding_width = (context_width - decision_width) // 2\n",
    "for file, yfile in zip(files, filesy):\n",
    "\n",
    "    imgX = rio.open(os.path.join(path, file)).read()\n",
    "    imgX = np.pad(imgX, ((0, 0), (padding_width, padding_width), (padding_width, padding_width)), mode='edge')\n",
    "    imgX = np.moveaxis(imgX, 0, -1)  # Move the channel dimension to the last position\n",
    "\n",
    "    imgY = rio.open(os.path.join(pathY, yfile)).read()\n",
    "    imgY = np.moveaxis(imgY, 0, -1)  # Move the channel dimension to the last position\n",
    "\n",
    "    print(file)\n",
    "\n",
    "    # color and display label\n",
    "\n",
    "    plt.imshow(imgY)\n",
    "    plt.title('image')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # predict full image\n",
    "    out = np.zeros((imgY.shape[0], imgY.shape[1], 1), dtype=np.float32)\n",
    "\n",
    "    for i in range(0, imgX.shape[0]-context_width, decision_width):\n",
    "        for j in range(0, imgX.shape[1]-context_width, decision_width):\n",
    "            x = torch.from_numpy(imgX[i:i + context_width, j:j + context_width, :]).float().to(device)\n",
    "            x = x.permute(2, 0, 1).unsqueeze(0)  # Add batch dimension and permute to (batch_size, channels, height, width)\n",
    "            \n",
    "            out1 = model(x)\n",
    "            out1 = out1.cpu().detach().numpy()\n",
    "            out[i:i + decision_width, j:j + decision_width, :] = out1.reshape(decision_width, decision_width, 7).argmax(axis=2).reshape(decision_width, decision_width, 1)    \n",
    "        \n",
    "        if i//decision_width % 5 == 0:\n",
    "            print(f\"{i/imgX.shape[0]*100:.2f}% done\")\n",
    "\n",
    "    output_path = os.path.join('../masksVGG/1/', file)\n",
    "    with rio.open(\n",
    "        output_path,\n",
    "        'w',\n",
    "        driver='GTiff',\n",
    "        height=out.shape[0],\n",
    "        width=out.shape[1],\n",
    "        count=1,\n",
    "        dtype=out.dtype,\n",
    "        crs=rio.open(os.path.join(path, file)).crs,\n",
    "        transform=rio.open(os.path.join(path, file)).transform,\n",
    "    ) as dst:\n",
    "        dst.write(out[:, :, 0], 1)\n",
    "        \n",
    "    colored_out = np.zeros((out.shape[0], out.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "    for class_id, color in classColors.items():\n",
    "        colored_out[out[:, :, 0] == class_id] = color\n",
    "\n",
    "    plt.imshow(colored_out)\n",
    "    plt.title('Colored Output')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(f'Image Segmentation Time: {time.time() - generation_start_time:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be744b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
